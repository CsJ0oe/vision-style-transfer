
@inproceedings{frigo_split_2016,
	address = {Las Vegas, NV, USA},
	title = {Split and {Match}: {Example}-{Based} {Adaptive} {Patch} {Sampling} for {Unsupervised} {Style} {Transfer}},
	isbn = {978-1-4673-8851-1},
	shorttitle = {Split and {Match}},
	url = {http://ieeexplore.ieee.org/document/7780435/},
	doi = {10.1109/CVPR.2016.66},
	urldate = {2020-12-01},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Frigo, Oriel and Sabater, Neus and Delon, Julie and Hellier, Pierre},
	month = jun,
	year = {2016},
	pages = {553--561},
	file = {Version soumise:/Users/gabrielnativel-fontaine/Zotero/storage/Z4XXXXLC/Frigo et al. - 2016 - Split and Match Example-Based Adaptive Patch Samp.pdf:application/pdf},
}

@article{elad_style-transfer_2017,
	title = {Style-{Transfer} via {Texture}-{Synthesis}},
	volume = {26},
	issn = {1057-7149, 1941-0042},
	url = {http://arxiv.org/abs/1609.03057},
	doi = {10.1109/TIP.2017.2678168},
	abstract = {Style-transfer is a process of migrating a style from a given image to the content of another, synthesizing a new image which is an artistic mixture of the two. Recent work on this problem adopting Convolutional Neural-networks (CNN) ignited a renewed interest in this field, due to the very impressive results obtained. There exists an alternative path towards handling the style-transfer task, via generalization of texture-synthesis algorithms. This approach has been proposed over the years, but its results are typically less impressive compared to the CNN ones. In this work we propose a novel style-transfer algorithm that extends the texture-synthesis work of Kwatra et. al. (2005), while aiming to get stylized images that get closer in quality to the CNN ones. We modify Kwatra's algorithm in several key ways in order to achieve the desired transfer, with emphasis on a consistent way for keeping the content intact in selected regions, while producing hallucinated and rich style in others. The results obtained are visually pleasing and diverse, shown to be competitive with the recent CNN style-transfer algorithms. The proposed algorithm is fast and flexible, being able to process any pair of content + style images.},
	number = {5},
	urldate = {2020-12-01},
	journal = {IEEE Transactions on Image Processing},
	author = {Elad, Michael and Milanfar, Peyman},
	month = may,
	year = {2017},
	note = {arXiv: 1609.03057},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {2338--2351},
	file = {arXiv Fulltext PDF:/Users/gabrielnativel-fontaine/Zotero/storage/L6BZLF86/Elad et Milanfar - 2017 - Style-Transfer via Texture-Synthesis.pdf:application/pdf;arXiv.org Snapshot:/Users/gabrielnativel-fontaine/Zotero/storage/WHAWFHGS/1609.html:text/html},
}

@article{gatys_neural_2015,
	title = {A {Neural} {Algorithm} of {Artistic} {Style}},
	url = {http://arxiv.org/abs/1508.06576},
	abstract = {In fine art, especially painting, humans have mastered the skill to create unique visual experiences through composing a complex interplay between the content and style of an image. Thus far the algorithmic basis of this process is unknown and there exists no artificial system with similar capabilities. However, in other key areas of visual perception such as object and face recognition near-human performance was recently demonstrated by a class of biologically inspired vision models called Deep Neural Networks. Here we introduce an artificial system based on a Deep Neural Network that creates artistic images of high perceptual quality. The system uses neural representations to separate and recombine content and style of arbitrary images, providing a neural algorithm for the creation of artistic images. Moreover, in light of the striking similarities between performance-optimised artificial neural networks and biological vision, our work offers a path forward to an algorithmic understanding of how humans create and perceive artistic imagery.},
	urldate = {2020-12-01},
	journal = {arXiv:1508.06576 [cs, q-bio]},
	author = {Gatys, Leon A. and Ecker, Alexander S. and Bethge, Matthias},
	month = sep,
	year = {2015},
	note = {arXiv: 1508.06576},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Neural and Evolutionary Computing, Quantitative Biology - Neurons and Cognition},
	file = {arXiv Fulltext PDF:/Users/gabrielnativel-fontaine/Zotero/storage/6W8DPV77/Gatys et al. - 2015 - A Neural Algorithm of Artistic Style.pdf:application/pdf;arXiv.org Snapshot:/Users/gabrielnativel-fontaine/Zotero/storage/88SSZQ72/1508.html:text/html},
}

@article{johnson_perceptual_2016,
	title = {Perceptual {Losses} for {Real}-{Time} {Style} {Transfer} and {Super}-{Resolution}},
	url = {http://arxiv.org/abs/1603.08155},
	abstract = {We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a {\textbackslash}emph\{per-pixel\} loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing {\textbackslash}emph\{perceptual\} loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.},
	urldate = {2020-12-01},
	journal = {arXiv:1603.08155 [cs]},
	author = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
	month = mar,
	year = {2016},
	note = {arXiv: 1603.08155},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
}
