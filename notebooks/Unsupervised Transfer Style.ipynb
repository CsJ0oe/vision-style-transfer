{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder transfer style\n",
    "Ce notebook est une implémentation de l'architecture décrite par A. Sanakoyeu, D. Kotovenko, S. Lang et B. Ommer dans *A Style-Aware Content Loss for Real-time HD Style Transfer* (2018).\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src='../latex/images/autoencoder.png'  />\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (128, 128, 3)\n",
    "input_content = tfl.Input(input_size)\n",
    "input_style = tfl.Input(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = tfl.Conv2D(32, (3, 3), strides=1, padding=\"same\")(input_content)\n",
    "n1 = tfl.BatchNormalization()(c1)\n",
    "a1 = tfl.LeakyReLU(alpha=0.2)(n1)\n",
    "\n",
    "c2 = tfl.Conv2D(64, (3, 3), strides=2, padding=\"same\")(a1)\n",
    "n2 = tfl.BatchNormalization()(c2)\n",
    "a2 = tfl.LeakyReLU(alpha=0.2)(n2)\n",
    "\n",
    "c3 = tfl.Conv2D(128, (3, 3), strides=2, padding=\"same\")(a2)\n",
    "n3 = tfl.BatchNormalization()(c3)\n",
    "a3 = tfl.LeakyReLU(alpha=0.2)(n3)\n",
    "\n",
    "c4 = tfl.Conv2D(512, (3, 3), strides=2, padding=\"same\")(a3)\n",
    "n4 = tfl.BatchNormalization()(c4)\n",
    "a4 = tfl.LeakyReLU(alpha=0.2)(n4)\n",
    "\n",
    "c5 = tfl.Conv2D(64, (3, 3), strides=2, padding=\"same\")(a4)\n",
    "n5 = tfl.BatchNormalization()(c5)\n",
    "a5 = tfl.LeakyReLU(alpha=0.2)(n5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Espace latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 16\n",
    "flat = tfl.Flatten()(a5)\n",
    "latent = tfl.Dense(latent_dim)(flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(input_content, latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_30 (LeakyReLU)   (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_31 (LeakyReLU)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_73 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_32 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_74 (Conv2D)           (None, 16, 16, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 16, 16, 512)       2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_33 (LeakyReLU)   (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 8, 8, 64)          294976    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_34 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                65552     \n",
      "=================================================================\n",
      "Total params: 1,047,312\n",
      "Trainable params: 1,045,712\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "decod_input = tfl.Input(latent_dim)\n",
    "shape_before_flat = K.int_shape(a5)\n",
    "shape_after_flat = K.int_shape(flat)\n",
    "d1 = tfl.Dense(shape_after_flat[1])(decod_input)\n",
    "\n",
    "reshape = tfl.Reshape((shape_before_flat[1], shape_before_flat[2], shape_before_flat[3]))(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf\n",
    "def residual_layer(input_layer):\n",
    "    res1 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(input_layer)\n",
    "    res2 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\")(res1)\n",
    "    add = tf.math.add(res2, input_layer)\n",
    "    out = tfl.ReLU()(add)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = residual_layer(reshape)\n",
    "r2 = residual_layer(r1)\n",
    "r3 = residual_layer(r2)\n",
    "r4 = residual_layer(r3)\n",
    "r5 = residual_layer(r4)\n",
    "r6 = residual_layer(r5)\n",
    "r7 = residual_layer(r6)\n",
    "r8 = residual_layer(r7)\n",
    "r9 = residual_layer(r8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(input_layer, filters):\n",
    "    layer_size = K.int_shape(input_layer)\n",
    "    resize = tf.image.resize(input_layer, (layer_size[1]*2, layer_size[1]*2) , method=\"nearest\")\n",
    "    conv = tfl.Conv2D(filters, (1, 1), strides=1, padding=\"same\")(resize)\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "up1 = upsampling_block(r9, 64)\n",
    "up2 = upsampling_block(up1, 64)\n",
    "up3 = upsampling_block(up2, 64)\n",
    "up4 = upsampling_block(up3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Model(decod_input, up4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4096)         69632       input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 8, 8, 64)     0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 64)     36928       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 64)     36928       conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_21 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_99[0][0]                  \n",
      "                                                                 reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_19 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_21[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_22 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_101[0][0]                 \n",
      "                                                                 re_lu_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_20 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_22[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_23 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_103[0][0]                 \n",
      "                                                                 re_lu_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_21 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_23[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_24 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_105[0][0]                 \n",
      "                                                                 re_lu_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_22 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_24[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_25 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_107[0][0]                 \n",
      "                                                                 re_lu_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_23 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_25[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_26 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_109[0][0]                 \n",
      "                                                                 re_lu_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_24 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_26[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_27 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_111[0][0]                 \n",
      "                                                                 re_lu_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_25 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_27[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_28 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_113[0][0]                 \n",
      "                                                                 re_lu_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_26 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_28[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 8, 8, 64)     36928       re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 8, 8, 64)     36928       conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Add_29 (TensorFlowO [(None, 8, 8, 64)]   0           conv2d_115[0][0]                 \n",
      "                                                                 re_lu_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_27 (ReLU)                 (None, 8, 8, 64)     0           tf_op_layer_Add_29[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeNearestNeighb [(None, 16, 16, 64)] 0           re_lu_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 16, 16, 64)   4160        tf_op_layer_ResizeNearestNeighbor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeNearestNeighb [(None, 32, 32, 64)] 0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 32, 32, 64)   4160        tf_op_layer_ResizeNearestNeighbor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeNearestNeighb [(None, 64, 64, 64)] 0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 64, 64, 64)   4160        tf_op_layer_ResizeNearestNeighbor\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ResizeNearestNeighb [(None, 128, 128, 64 0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 128, 128, 3)  195         tf_op_layer_ResizeNearestNeighbor\n",
      "==================================================================================================\n",
      "Total params: 747,011\n",
      "Trainable params: 747,011\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_discriminator = tfl.Input(input_size)\n",
    "conv1 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(input_discriminator)\n",
    "conv2 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(conv1)\n",
    "conv3 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(conv2)\n",
    "conv4 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(conv3)\n",
    "conv5 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(conv4)\n",
    "conv6 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"relu\")(conv5)\n",
    "conv7 = tfl.Conv2D(64, (3, 3), strides=1, padding=\"same\", activation=\"sigmoid\")(conv6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Model(input_discriminator, conv7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d_120 (Conv2D)          (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_123 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_124 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_125 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "conv2d_126 (Conv2D)          (None, 128, 128, 64)      36928     \n",
      "=================================================================\n",
      "Total params: 223,360\n",
      "Trainable params: 223,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les fonctions de coût\n",
    "### Style-Aware Content Loss\n",
    "$$\n",
    "\\mathcal{L}_c(E, G)=\\underset{x\\sim p_{X}(x)}{\\mathbb{E}}\\left[\\frac{1}{d}|| E(x) - E(G(E(x))) ||^2_2\\right]\n",
    "$$\n",
    "Elle représente la distance euclidienne normalisée entre l'encodage de l'image d'example $x$ et l'encodage de l'image reconstruite $G(E(x))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_aware_content_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed Image Loss\n",
    "$$\n",
    "\\mathcal{L}_T(E,G) = \\underset{x\\sim p_{X}(x)}{\\mathbb{E}}\\left[\\frac{1}{CHW}|| T(x) - T(G(E(x))) ||^2_2\\right]\n",
    "$$\n",
    "Elle représente la différence entre l'image après une transformation T et l'image reconstruite après la même transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformed_image_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator Loss\n",
    "Standard Adversarial Discriminator\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_D(E, G, D) = \\underset{x\\sim p_{Y}(y)}{\\mathbb{E}}\\left[\\log D(y)\\right] + \\underset{x\\sim p_{X}(x)}{\\mathbb{E}}\\left[\\log (1 - D(G(E(x))))\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_loss():\n",
    "    return discriminator_loss() + transformed_image_loss() + style_aware_content_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 300000\n",
    "for epoch in range(epochs):\n",
    "    for image, content in train:\n",
    "        with tf.GradientTape() as tape:\n",
    "            out_encoder = encoder(content, training=True)\n",
    "            out_decoder = decoder(out_encoder, training=True)\n",
    "            encode_decoded = encoder(out_decoder, training=True)\n",
    "            \n",
    "            discr1 = discriminator(content, training=True)\n",
    "            discr2 = discriminator(out_decoder, training=True)\n",
    "            discr3 = discriminator(style, training=True)\n",
    "            \n",
    "            discr_loss = discriminator_loss()\n",
    "            transformed_loss = transformed_image_loss()\n",
    "            style_aware_loss = style_aware_content_loss()\n",
    "            \n",
    "            loss_value = discr_loss + transformed_loss + style_aware_loss\n",
    "            \n",
    "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    \n",
    "    if epoch == 200000:\n",
    "        optimizer.lr.assign(0.00002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
